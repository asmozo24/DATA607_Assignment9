---
title: "Web APIs"
author: "Alexis Mekueko"
date: "10/23/2020"
output:
  slidy_presentation: default
  html_document:
    df_print: paged
  beamer_presentation: default
  pdf_document: default
  ioslides_presentation: default
header-includes:
- \usepackage{tikz}
- \usetikzlibrary{positioning,shapes.multipart,shapes}
---




```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## R Packages

```{r load-packages, message=FALSE}

library(tidyverse) #loading all library needed for this assignment
#library(openintro)
#head(fastfood)
library(readxl)
#library(data.table)
library(DT)
library(knitr)

library(readr)
#library(plyr)
library(dplyr)
library(stringr)
library(XML)
library(RCurl)
library(jsonlite)
library(httr)

#library(maps)
#library(dice)
# #library(VennDiagram)
# #library(help = "dice")
#ibrary(DBI)
#library(dbplyr)

# library(rstudioapi)
# library(RJDBC)
# library(odbc)
# library(RSQLite)
# #library(rvest)

#library(readtext)
#library(ggpubr)
#library(fitdistrplus)
#library(ggplot2)
#library(moments)
#library(qualityTools)
#library(normalp)
#library(utils)
#library(MASS)
#library(qqplotr)
#library(DATA606)

```

Github Link: https://github.com/asmozo24/DATA607_Assignment9.git

Web link: 




# Description
This assignment of week 9 is about practicing web API calls. How to get web API in R. 
Approach: I signed up on New York Time to get an API key. there are various option group in category. I chose the "most "Most Popular" and played around to see what I can get for news. I used GET() for httr request functions on the most shared news within 7days on facebook. 
glimpse(NyTimes_newsJ) display all the 20 observations of  22 variables. Now I want to print out a link to let's say a news 

```{r}


NyTimes_newsRaw <- GET("https://api.nytimes.com/svc/mostpopular/v2/shared/7/facebook.json?api-key=K2Yl3COR8LJh0kxjVuyWWb9svbI1NyWj") 
NyTimes_newsRaw
print("Response object from GET(), status: 200 means the GET() call was successful")


#Just to see how the header looks like
headers(NyTimes_newsRaw)

 # getting content .....str(NyTimes_newsC)
NyTimes_newsC <- content(NyTimes_newsRaw, as = 'text') 

NyTimes_newsJ <- fromJSON(NyTimes_newsC)

# THIS GIVES me an overview of content
glimpse(NyTimes_newsJ) 
#names(NyTimes_newsJ) 

sampl1 <- NyTimes_newsJ$results$url[1]  # use $ to print the first link 
#cat("The most popular article from New York Times shared on facebook is: ",  sampl1)

# most viewed article on New York Times
NyTimes_newsRaw2 <- GET("https://api.nytimes.com/svc/mostpopular/v2/viewed/1.json?api-key=K2Yl3COR8LJh0kxjVuyWWb9svbI1NyWj") 
#print("Response object from GET(), status: 200 means the GET() call was successful")

#headers(NyTimes_newsRaw2)
NyTimes_newsC2 <- content(NyTimes_newsRaw2, as = 'text')  # getting content
#str(NyTimes_newsC2)

NyTimes_newsJ2 <- fromJSON(NyTimes_newsC2)
sampl2 <- NyTimes_newsJ2$results$url[1]

#cat("The most viewed article on The New York Times is :") 




```

```{r, results="asis", echo=FALSE}

cat(paste0("The most popular article from New York Times shared on facebook: ","[", "[click here]", "](", sampl1, ")","\n"), "\n")
cat(paste0("The most viewed article on The New York Times: ","[", "[click here]", "](",sampl2, ")","\n"))


```


                   

#Conclusion: The New York Times API can be easy to use in scraping articles published on their website. However, I think the website it is pretty nested and need a better understanding of the New York Times website structure. 

\tikzset{basic/.style={
        draw,
        rectangle split,
        rectangle split parts=2,
        rectangle split part fill={blue!20,white},
        minimum width=2.5cm,
        text width=2cm,
        align=left,
        font=\itshape
    },
    Diamond/.style={ diamond, 
                        draw, 
                        shape aspect=2, 
                        inner sep = 2pt,
                        text centered,
                        fill=blue!10!white,
                        font=\itshape
                      }
        }


